{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MinMaxScaler  # StandardScalerからMinMaxScalerに変更\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === データの前処理 ===\n",
    "\n",
    "# Ageの処理\n",
    "from kanjize import number2kanji, kanji2number\n",
    "import re\n",
    "import jaconv  # 日本語の全角・半角変換ライブラリ\n",
    "\n",
    "def clean_age_extended(age):\n",
    "    if pd.isnull(age):\n",
    "        return None\n",
    "    if '歳' in age:\n",
    "        age = re.sub(\"歳\", \"\", str(age))\n",
    "    if '才' in age:\n",
    "        age = re.sub(\"才\", \"\", str(age))\n",
    "    if '際' in age:\n",
    "        age = re.sub(\"際\", \"\", str(age))\n",
    "\n",
    "    # 「10代」や「20代」の処理\n",
    "    if \"代\" in age:\n",
    "        try:\n",
    "            base_age = int(re.sub(\"代\", \"\", age))\n",
    "            return base_age + 5  # 例えば「10代」は平均15歳とする\n",
    "        except ValueError:\n",
    "            return None\n",
    "    # 半角数字の場合はそのまま数値に変換\n",
    "    try:\n",
    "        return int(age)\n",
    "    except ValueError:\n",
    "        # 漢数字をアラビア数字に変換\n",
    "        return kanji2number(age)\n",
    "# 例としてデータを変換\n",
    "train['Age'] = train['Age'].apply(clean_age_extended)\n",
    "test['Age'] = test['Age'].apply(clean_age_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypeofContactの処理(ラベルエンコーディング)\n",
    "train['TypeofContact'].fillna('Self Enquiry', inplace = True)\n",
    "test['TypeofContact'].fillna('Self Enquiry', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CityTierの処理\n",
    "# そのまま使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DurationOfPitchの処理 \n",
    "def clean_duration(duration):\n",
    "    if pd.isna(duration):\n",
    "        return np.nan\n",
    "    duration_str = str(duration)\n",
    "    if '分' in duration_str:\n",
    "        num = float(''.join(filter(str.isdigit, duration_str)))\n",
    "        return num * 60\n",
    "    elif '秒' in duration_str:\n",
    "        return float(''.join(filter(str.isdigit, duration_str)))\n",
    "    return np.nan\n",
    "train['DurationOfPitch'] = train['DurationOfPitch'].apply(clean_duration)\n",
    "test['DurationOfPitch'] = test['DurationOfPitch'].apply(clean_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupation(ラベルエンコーディング)\n",
    "# そのまま"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender(ラベルエンコーディング)\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_category_gender(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    # maleに関連する単語が含まれていればmale\n",
    "    if any(word in text for word in ['Female', 'Ｆｅ\\u3000Ｍａｌｅ','fe male', 'Ｆｅｍａｌｅ','ＦＥ\\u3000ＭＡＬＥ', 'female', 'ｆｅ\\u3000ｍａｌｅ', 'ｆｅｍａｌｅ', 'FEMALE', 'FE MALE','ＦＥＭＡＬＥ', 'Fe Male']):\n",
    "        return 'female'\n",
    "    elif any(word in text for word in ['Ｍａｌｅ','male', 'ｍａｌｅ','MALE','ＭＡＬＥ', 'Male'])and 'female' not in text:\n",
    "        return 'male'\n",
    "    return 'unknown'  # その他の場合\n",
    "\n",
    "# DataFrameでの使用例\n",
    "def normalize_product_column_gender(df, column_name):\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].apply(normalize_category_gender)\n",
    "    return df\n",
    "train = normalize_product_column_gender(train, 'Gender')\n",
    "test = normalize_product_column_gender(test, 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumberOfPersonVisiting\n",
    "# そのまま"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumberOfPersonFollowups\n",
    "outliers = [100, 200, 300, 400, 500, 600]\n",
    "train['NumberOfFollowups'] = train['NumberOfFollowups'].replace(outliers, np.nan)\n",
    "test['NumberOfFollowups'] = test['NumberOfFollowups'].replace(outliers, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProductPitched(ラベルエンコーディング)\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_category(text):\n",
    "    \"\"\"\n",
    "    カテゴリー名を標準化する関数\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): 入力カテゴリー文字列\n",
    "    \n",
    "    Returns:\n",
    "        str: 標準化されたカテゴリー名（'basic', 'standard', 'deluxe', 'super deluxe', 'king'のいずれか）\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    # 前処理\n",
    "    # 1. 小文字化\n",
    "    # 2. 全角文字を半角に変換\n",
    "    # 3. 特殊文字の正規化\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    # 特殊文字や記号を通常のアルファベットに置換\n",
    "    text = re.sub(r'[|×]', 'x', text)\n",
    "    text = re.sub(r'[ıіℹ]', 'i', text)\n",
    "    text = re.sub(r'[ꓢѕs]', 's', text)\n",
    "    text = re.sub(r'[աꭰdԁ]', 'd', text)\n",
    "    text = re.sub(r'[եℯeє]', 'e', text)\n",
    "    text = re.sub(r'[ᗞ]', 'd', text)\n",
    "    text = re.sub(r'[լl]', 'l', text)\n",
    "    text = re.sub(r'[υu]', 'u', text)\n",
    "    text = re.sub(r'[χx]', 'x', text)\n",
    "    text = re.sub(r'[նn]', 'n', text)\n",
    "    text = re.sub(r'[գg]', 'g', text)\n",
    "    text = re.sub(r'[բb]', 'b', text)\n",
    "    text = re.sub(r'[αа]', 'a', text)\n",
    "    text = re.sub(r'[ϲс]', 'c', text)\n",
    "    \n",
    "    # スペースの正規化\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # カテゴリーの判定\n",
    "    if any(word in text for word in ['basic', 'basix','basιc','baտic','basiς','βasic','basic','𐊡asic', 'вasic',]):\n",
    "        return 'basic'\n",
    "    elif any(word in text for word in ['super Deluxe','super dεluxe','super dexuxe''super deluxe']):\n",
    "        return 'super deluxe'\n",
    "    elif any(word in text for word in ['deluxε','dεluxε','deluxe', 'dexuxe', 'Deluxe'])and 'super deluxe' not in text:\n",
    "        return 'deluxe'\n",
    "    elif any(word in text for word in ['standard','standard','տtandard','staոdard']):\n",
    "        return 'standard'\n",
    "    elif any(word in text for word in ['kiոg','king','king']):\n",
    "        return 'king'\n",
    "    \n",
    "    return text\n",
    "# DataFrameでの使用例\n",
    "def normalize_product_column(df, column_name):\n",
    "    \"\"\"\n",
    "    DataFrameの特定のカラムのカテゴリーを標準化する関数\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): 入力データフレーム\n",
    "        column_name (str): 標準化対象のカラム名\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: カラムが標準化されたデータフレーム\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].apply(normalize_category)\n",
    "    return df\n",
    "\n",
    "# 使用例\n",
    "train = normalize_product_column(train, 'ProductPitched')\n",
    "test = normalize_product_column(test, 'ProductPitched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreferredPropertyStar\n",
    "#そのまま"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NumberOfTrips\n",
    "def preprocess(value):\n",
    "    # 値がfloat型の場合は文字列に変換\n",
    "    if isinstance(value, float):\n",
    "        value = str(value)\n",
    "    # 数字のみの場合\n",
    "    if re.match(r\"^\\d+$\", value):\n",
    "        return int(value)\n",
    "    \n",
    "    # \"年に\"が含まれる場合\n",
    "    elif \"年に\" in value:\n",
    "        times = int(re.search(r\"(\\d+)\", value).group(1))\n",
    "        return times \n",
    "    \n",
    "    # \"半年に\"が含まれる場合\n",
    "    elif \"半年に\" in value:\n",
    "        times = int(re.search(r\"(\\d+)\", value).group(1))\n",
    "        return times * 2\n",
    "    \n",
    "    # その他の場合はNoneを返す\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "train['NumberOfTrips'] = train['NumberOfTrips'].apply(preprocess)\n",
    "test['NumberOfTrips'] = test['NumberOfTrips'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passport\n",
    "#そのまま"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PitchSatisfactionScore\n",
    "#そのまま"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designation(ラベルエンコーディング)\n",
    "#そのまま"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MonthlyIncome\n",
    "def clean_income(income):\n",
    "    if pd.isna(income):\n",
    "        return np.nan\n",
    "    income_str = str(income).replace(' ', '').replace(',', '')\n",
    "    if '万円' in income_str:\n",
    "        num = float(''.join(filter(str.isdigit, income_str)))\n",
    "        return num * 1000\n",
    "    return float(''.join(filter(str.isdigit, income_str))) / 10\n",
    "\n",
    "\n",
    "train['MonthlyIncome'] = train['MonthlyIncome'].apply(clean_income)\n",
    "test['MonthlyIncome'] = test['MonthlyIncome'].apply(clean_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_infoの前処理\n",
    "# 前処理関数\n",
    "def preprocess(row):\n",
    "    row = re.sub(r'[、,／／\\t\\n]', ' ', row)  # 区切り記号を統一\n",
    "    row = re.sub(r'\\s+', ' ', row).strip()  # 余分な空白を削除\n",
    "    \n",
    "    # 婚姻状況\n",
    "    if re.search(r'(未婚)', row):\n",
    "        marital_status = '未婚'\n",
    "    elif re.search(r'(独身)',row):\n",
    "        marital_status = '独身'\n",
    "    elif re.search(r'(結婚済み)',row):\n",
    "        marital_status = '結婚済み'\n",
    "    elif re.search(r'(離婚済み)',row):\n",
    "        marital_status = '離婚済み'\n",
    "    else:\n",
    "        marital_status = row\n",
    "    \n",
    "    # 車の所有状況\n",
    "    if re.search(r'(車保有なし|車未所有|車未所持|車なし|乗用車なし)', row):\n",
    "        car_status = '未所持'\n",
    "    elif re.search(r'(車保有|車所持|自動車所有|車あり|自家用車あり)',row):\n",
    "        car_status = '所持'\n",
    "    else:\n",
    "        car_status = row\n",
    "    \n",
    "    # 子供の人数\n",
    "    child_match = re.search(r'(\\d+)(人|児)', row)\n",
    "    child_count = int(child_match.group(1)) if child_match else 0\n",
    "    \n",
    "    return [marital_status, car_status, child_count]\n",
    "\n",
    "train[['married', 'car', 'child']] = train['customer_info'].apply(preprocess).apply(pd.Series)\n",
    "test[['married', 'car', 'child']] = test['customer_info'].apply(preprocess).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#欠損値を平均値で置き換える\n",
    "numerical_columns = ['Age', 'DurationOfPitch', 'MonthlyIncome','NumberOfFollowups', 'NumberOfTrips']\n",
    "#実験, 'NumberOfFollowups', 'NumberOfTrips'\n",
    "for col in numerical_columns:\n",
    "    median_value = train[col].median()\n",
    "    train[col].fillna(median_value, inplace=True)\n",
    "    test[col].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_bin'] = pd.cut(train['Age'], bins=5, labels=False)\n",
    "test['age_bin'] = pd.cut(test['Age'], bins=5, labels=False)\n",
    "train['income_bin'] = pd.cut(train['MonthlyIncome'], bins=5, labels=False)\n",
    "test['income_bin'] = pd.cut(test['MonthlyIncome'], bins=5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルに使用する特徴量の選択\n",
    "feature_columns = ['Age', 'CityTier', 'NumberOfPersonVisiting',\n",
    "                  'NumberOfFollowups', 'PreferredPropertyStar', 'NumberOfTrips',\n",
    "                  'DurationOfPitch', 'Passport', 'PitchSatisfactionScore', 'MonthlyIncome',\n",
    "                  'TypeofContact', 'Occupation', 'Gender', 'ProductPitched', 'Designation',\n",
    "                  'married', 'car', 'child','age_bin','income_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[feature_columns]\n",
    "y = train['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層化k-foldの初期化\n",
    "skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostのパラメータ設定\n",
    "params_cat = {\n",
    "    'iterations': 1000,\n",
    "    'random_seed': 42,\n",
    "    'eval_metric': 'AUC',\n",
    "    'early_stopping_rounds': 50,\n",
    "    'verbose': 100,\n",
    "    'task_type': 'CPU',\n",
    "    'bagging_temperature': 0, \n",
    "    'border_count': 128, \n",
    "    #4\n",
    "    'depth': 1, \n",
    "    'iterations': 200, \n",
    "    'l2_leaf_reg': 3, \n",
    "    'learning_rate': 1, \n",
    "    #0.05\n",
    "    'max_leaves': 31, \n",
    "    'min_data_in_leaf': 1, \n",
    "    'random_strength': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_cat(model, X_new):\n",
    "    \"\"\"\n",
    "    CatBoostモデルを使用して新しいデータの予測確率を返す関数\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : CatBoostClassifier\n",
    "        学習済みのCatBoostモデル\n",
    "    X_new : array-like\n",
    "        予測したい新しいデータ\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    array-like\n",
    "        陽性クラスの予測確率\n",
    "    \"\"\"\n",
    "    return model.predict_proba(X_new)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_auc_cat = []\n",
    "fold_auc_cat_after = []\n",
    "models_cat = []\n",
    "models_cat_cali = []\n",
    "# カテゴリカル変数のインデックスリスト（存在する場合）\n",
    "cat_features = ['TypeofContact', \n",
    "                'Occupation', \n",
    "                'Gender',\n",
    "                'Passport',\n",
    "                'ProductPitched', \n",
    "                'Designation' , \n",
    "                'married',\n",
    "                'car',\n",
    "                'age_bin','income_bin',\n",
    "                ]  # カテゴリカル変数のカラムインデックスを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "0:\ttest: 0.5058740\tbest: 0.5058740 (0)\ttotal: 2.33ms\tremaining: 465ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8496445966\n",
      "bestIteration = 29\n",
      "\n",
      "Shrink model to first 30 iterations.\n",
      "Fold 1 AUC: 0.8518658681058313\n",
      "Fold 2\n",
      "0:\ttest: 0.5105798\tbest: 0.5105798 (0)\ttotal: 1.64ms\tremaining: 327ms\n",
      "100:\ttest: 0.8307556\tbest: 0.8430960 (52)\ttotal: 135ms\tremaining: 132ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8430959589\n",
      "bestIteration = 52\n",
      "\n",
      "Shrink model to first 53 iterations.\n",
      "Fold 2 AUC: 0.8451526918520469\n",
      "Fold 3\n",
      "0:\ttest: 0.5094116\tbest: 0.5094116 (0)\ttotal: 1.25ms\tremaining: 248ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8432275898\n",
      "bestIteration = 13\n",
      "\n",
      "Shrink model to first 14 iterations.\n",
      "Fold 3 AUC: 0.8441325523232854\n",
      "Fold 4\n",
      "0:\ttest: 0.6986674\tbest: 0.6986674 (0)\ttotal: 1.47ms\tremaining: 293ms\n",
      "100:\ttest: 0.8233005\tbest: 0.8352904 (54)\ttotal: 146ms\tremaining: 143ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8352904311\n",
      "bestIteration = 54\n",
      "\n",
      "Shrink model to first 55 iterations.\n",
      "Fold 4 AUC: 0.8336741762047697\n",
      "Fold 5\n",
      "0:\ttest: 0.7268529\tbest: 0.7268529 (0)\ttotal: 2.09ms\tremaining: 417ms\n",
      "100:\ttest: 0.8272586\tbest: 0.8367583 (68)\ttotal: 148ms\tremaining: 145ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8367582544\n",
      "bestIteration = 68\n",
      "\n",
      "Shrink model to first 69 iterations.\n",
      "Fold 5 AUC: 0.835109014744203\n",
      "Fold 6\n",
      "0:\ttest: 0.6421810\tbest: 0.6421810 (0)\ttotal: 1.37ms\tremaining: 273ms\n",
      "100:\ttest: 0.8841244\tbest: 0.9053666 (62)\ttotal: 126ms\tremaining: 124ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.905366626\n",
      "bestIteration = 62\n",
      "\n",
      "Shrink model to first 63 iterations.\n",
      "Fold 6 AUC: 0.9006827852360062\n",
      "Fold 7\n",
      "0:\ttest: 0.6904377\tbest: 0.6904377 (0)\ttotal: 1.83ms\tremaining: 365ms\n",
      "100:\ttest: 0.8220470\tbest: 0.8239931 (64)\ttotal: 206ms\tremaining: 202ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8247517894\n",
      "bestIteration = 103\n",
      "\n",
      "Shrink model to first 104 iterations.\n",
      "Fold 7 AUC: 0.8237622456047763\n"
     ]
    }
   ],
   "source": [
    "# 交差検証\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    \n",
    "    # データ分割\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # CatBoost用のデータセット作成\n",
    "    train_pool = Pool(\n",
    "        data=X_train,\n",
    "        label=y_train,\n",
    "        cat_features=cat_features\n",
    "    )\n",
    "    valid_pool = Pool(\n",
    "        data=X_valid,\n",
    "        label=y_valid,\n",
    "        cat_features=cat_features\n",
    "    )\n",
    "    \n",
    "    # モデルのインスタンス化と学習\n",
    "    model = CatBoostClassifier(**params_cat)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=valid_pool,\n",
    "        use_best_model=True,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    # 検証データでの確率予測\n",
    "    y_pred_prob = predict_proba_cat(model, X_valid)\n",
    "\n",
    "    # キャリブレーションの実行\n",
    "    calibrated_model = CalibratedClassifierCV(\n",
    "        model, \n",
    "        method='isotonic',  # または 'isotonic'\n",
    "        cv='prefit'  # すでに学習済みのモデルを使用\n",
    "        )\n",
    "    \n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    pred_proba_calibrated = calibrated_model.predict_proba(X_valid)[:, 1]\n",
    "    auc_after = roc_auc_score(y_valid, pred_proba_calibrated)\n",
    "    \n",
    "    # AUC計算\n",
    "    auc = roc_auc_score(y_valid, y_pred_prob)\n",
    "    print(f\"Fold {fold+1} AUC: {auc_after}\")\n",
    "    fold_auc_cat.append(auc)\n",
    "    fold_auc_cat_after.append(auc_after)\n",
    "    models_cat.append(model)\n",
    "    models_cat_cali.append(calibrated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8496445965512702,\n",
       " 0.8430959589311571,\n",
       " 0.843227589838094,\n",
       " 0.8352904311112577,\n",
       " 0.836758254444701,\n",
       " 0.9053666259854206,\n",
       " 0.8247517894250749,\n",
       " 0.8518658681058313,\n",
       " 0.8451526918520469,\n",
       " 0.8441325523232854,\n",
       " 0.8336741762047697,\n",
       " 0.835109014744203,\n",
       " 0.9006827852360062,\n",
       " 0.8237622456047763]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_auc = fold_auc_cat + fold_auc_cat_after\n",
    "all_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.8480 (±0.0238)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x17a1cf470>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x179a87e30>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x171fc2540>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x17a3ef740>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x17a1cd430>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x179d0b5f0>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x17b3e30e0>,\n",
       "                        method='isotonic'),\n",
       " <catboost.core.CatBoostClassifier at 0x17a1cf470>,\n",
       " <catboost.core.CatBoostClassifier at 0x179a87e30>,\n",
       " <catboost.core.CatBoostClassifier at 0x171fc2540>,\n",
       " <catboost.core.CatBoostClassifier at 0x17a3ef740>,\n",
       " <catboost.core.CatBoostClassifier at 0x17a1cd430>,\n",
       " <catboost.core.CatBoostClassifier at 0x179d0b5f0>,\n",
       " <catboost.core.CatBoostClassifier at 0x17b3e30e0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全foldの平均AUCを計算\n",
    "mean_auc = np.mean(all_auc)\n",
    "std_auc = np.std(all_auc)\n",
    "print(f\"\\nMean AUC: {mean_auc:.4f} (±{std_auc:.4f})\")\n",
    "models_cat_cali_all = models_cat_cali + models_cat\n",
    "models_cat_cali_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータでの予測\n",
    "test_preds_cat_cali_all = np.mean([predict_proba_cat(model, test[feature_columns]) for model in models_cat_cali_all], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイルの作成\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'ProdTaken': test_preds_cat_cali_all\n",
    "})\n",
    "submission.to_csv('submission_catcali_all_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
