{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MinMaxScaler  # StandardScalerã‹ã‚‰MinMaxScalerã«å¤‰æ›´\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç† ===\n",
    "\n",
    "# Ageã®å‡¦ç†\n",
    "from kanjize import number2kanji, kanji2number\n",
    "import re\n",
    "import jaconv  # æ—¥æœ¬èªã®å…¨è§’ãƒ»åŠè§’å¤‰æ›ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "\n",
    "def clean_age_extended(age):\n",
    "    if pd.isnull(age):\n",
    "        return None\n",
    "    if 'æ­³' in age:\n",
    "        age = re.sub(\"æ­³\", \"\", str(age))\n",
    "    if 'æ‰' in age:\n",
    "        age = re.sub(\"æ‰\", \"\", str(age))\n",
    "    if 'éš›' in age:\n",
    "        age = re.sub(\"éš›\", \"\", str(age))\n",
    "\n",
    "    # ã€Œ10ä»£ã€ã‚„ã€Œ20ä»£ã€ã®å‡¦ç†\n",
    "    if \"ä»£\" in age:\n",
    "        try:\n",
    "            base_age = int(re.sub(\"ä»£\", \"\", age))\n",
    "            return base_age + 5  # ä¾‹ãˆã°ã€Œ10ä»£ã€ã¯å¹³å‡15æ­³ã¨ã™ã‚‹\n",
    "        except ValueError:\n",
    "            return None\n",
    "    # åŠè§’æ•°å­—ã®å ´åˆã¯ãã®ã¾ã¾æ•°å€¤ã«å¤‰æ›\n",
    "    try:\n",
    "        return int(age)\n",
    "    except ValueError:\n",
    "        # æ¼¢æ•°å­—ã‚’ã‚¢ãƒ©ãƒ“ã‚¢æ•°å­—ã«å¤‰æ›\n",
    "        return kanji2number(age)\n",
    "# ä¾‹ã¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›\n",
    "train['Age'] = train['Age'].apply(clean_age_extended)\n",
    "test['Age'] = test['Age'].apply(clean_age_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypeofContactã®å‡¦ç†(ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°)\n",
    "train['TypeofContact'].fillna('Self Enquiry', inplace = True)\n",
    "test['TypeofContact'].fillna('Self Enquiry', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CityTierã®å‡¦ç†\n",
    "# ãã®ã¾ã¾ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DurationOfPitchã®å‡¦ç† \n",
    "def clean_duration(duration):\n",
    "    if pd.isna(duration):\n",
    "        return np.nan\n",
    "    duration_str = str(duration)\n",
    "    if 'åˆ†' in duration_str:\n",
    "        num = float(''.join(filter(str.isdigit, duration_str)))\n",
    "        return num * 60\n",
    "    elif 'ç§’' in duration_str:\n",
    "        return float(''.join(filter(str.isdigit, duration_str)))\n",
    "    return np.nan\n",
    "train['DurationOfPitch'] = train['DurationOfPitch'].apply(clean_duration)\n",
    "test['DurationOfPitch'] = test['DurationOfPitch'].apply(clean_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupation(ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°)\n",
    "# ãã®ã¾ã¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender(ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°)\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_category_gender(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    # maleã«é–¢é€£ã™ã‚‹å˜èªãŒå«ã¾ã‚Œã¦ã„ã‚Œã°male\n",
    "    if any(word in text for word in ['Female', 'ï¼¦ï½…\\u3000ï¼­ï½ï½Œï½…','fe male', 'ï¼¦ï½…ï½ï½ï½Œï½…','ï¼¦ï¼¥\\u3000ï¼­ï¼¡ï¼¬ï¼¥', 'female', 'ï½†ï½…\\u3000ï½ï½ï½Œï½…', 'ï½†ï½…ï½ï½ï½Œï½…', 'FEMALE', 'FE MALE','ï¼¦ï¼¥ï¼­ï¼¡ï¼¬ï¼¥', 'Fe Male']):\n",
    "        return 'female'\n",
    "    elif any(word in text for word in ['ï¼­ï½ï½Œï½…','male', 'ï½ï½ï½Œï½…','MALE','ï¼­ï¼¡ï¼¬ï¼¥', 'Male'])and 'female' not in text:\n",
    "        return 'male'\n",
    "    return 'unknown'  # ãã®ä»–ã®å ´åˆ\n",
    "\n",
    "# DataFrameã§ã®ä½¿ç”¨ä¾‹\n",
    "def normalize_product_column_gender(df, column_name):\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].apply(normalize_category_gender)\n",
    "    return df\n",
    "train = normalize_product_column_gender(train, 'Gender')\n",
    "test = normalize_product_column_gender(test, 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumberOfPersonVisiting\n",
    "# ãã®ã¾ã¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumberOfPersonFollowups\n",
    "outliers = [100, 200, 300, 400, 500, 600]\n",
    "train['NumberOfFollowups'] = train['NumberOfFollowups'].replace(outliers, np.nan)\n",
    "test['NumberOfFollowups'] = test['NumberOfFollowups'].replace(outliers, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProductPitched(ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°)\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_category(text):\n",
    "    \"\"\"\n",
    "    ã‚«ãƒ†ã‚´ãƒªãƒ¼åã‚’æ¨™æº–åŒ–ã™ã‚‹é–¢æ•°\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): å…¥åŠ›ã‚«ãƒ†ã‚´ãƒªãƒ¼æ–‡å­—åˆ—\n",
    "    \n",
    "    Returns:\n",
    "        str: æ¨™æº–åŒ–ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªãƒ¼åï¼ˆ'basic', 'standard', 'deluxe', 'super deluxe', 'king'ã®ã„ãšã‚Œã‹ï¼‰\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    \n",
    "    # å‰å‡¦ç†\n",
    "    # 1. å°æ–‡å­—åŒ–\n",
    "    # 2. å…¨è§’æ–‡å­—ã‚’åŠè§’ã«å¤‰æ›\n",
    "    # 3. ç‰¹æ®Šæ–‡å­—ã®æ­£è¦åŒ–\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    # ç‰¹æ®Šæ–‡å­—ã‚„è¨˜å·ã‚’é€šå¸¸ã®ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã«ç½®æ›\n",
    "    text = re.sub(r'[|Ã—]', 'x', text)\n",
    "    text = re.sub(r'[Ä±Ñ–â„¹]', 'i', text)\n",
    "    text = re.sub(r'[ê“¢Ñ•s]', 's', text)\n",
    "    text = re.sub(r'[Õ¡ê­°dÔ]', 'd', text)\n",
    "    text = re.sub(r'[Õ¥â„¯eÑ”]', 'e', text)\n",
    "    text = re.sub(r'[á—]', 'd', text)\n",
    "    text = re.sub(r'[Õ¬l]', 'l', text)\n",
    "    text = re.sub(r'[Ï…u]', 'u', text)\n",
    "    text = re.sub(r'[Ï‡x]', 'x', text)\n",
    "    text = re.sub(r'[Õ¶n]', 'n', text)\n",
    "    text = re.sub(r'[Õ£g]', 'g', text)\n",
    "    text = re.sub(r'[Õ¢b]', 'b', text)\n",
    "    text = re.sub(r'[Î±Ğ°]', 'a', text)\n",
    "    text = re.sub(r'[Ï²Ñ]', 'c', text)\n",
    "    \n",
    "    # ã‚¹ãƒšãƒ¼ã‚¹ã®æ­£è¦åŒ–\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®åˆ¤å®š\n",
    "    if any(word in text for word in ['basic', 'basix','basÎ¹c','baÕ¿ic','basiÏ‚','Î²asic','basic','ğŠ¡asic', 'Ğ²asic',]):\n",
    "        return 'basic'\n",
    "    elif any(word in text for word in ['super Deluxe','super dÎµluxe','super dexuxe''super deluxe']):\n",
    "        return 'super deluxe'\n",
    "    elif any(word in text for word in ['deluxÎµ','dÎµluxÎµ','deluxe', 'dexuxe', 'Deluxe'])and 'super deluxe' not in text:\n",
    "        return 'deluxe'\n",
    "    elif any(word in text for word in ['standard','standard','Õ¿tandard','staÕ¸dard']):\n",
    "        return 'standard'\n",
    "    elif any(word in text for word in ['kiÕ¸g','king','king']):\n",
    "        return 'king'\n",
    "    \n",
    "    return text\n",
    "# DataFrameã§ã®ä½¿ç”¨ä¾‹\n",
    "def normalize_product_column(df, column_name):\n",
    "    \"\"\"\n",
    "    DataFrameã®ç‰¹å®šã®ã‚«ãƒ©ãƒ ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ¨™æº–åŒ–ã™ã‚‹é–¢æ•°\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        column_name (str): æ¨™æº–åŒ–å¯¾è±¡ã®ã‚«ãƒ©ãƒ å\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: ã‚«ãƒ©ãƒ ãŒæ¨™æº–åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].apply(normalize_category)\n",
    "    return df\n",
    "\n",
    "# ä½¿ç”¨ä¾‹\n",
    "train = normalize_product_column(train, 'ProductPitched')\n",
    "test = normalize_product_column(test, 'ProductPitched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreferredPropertyStar\n",
    "#ãã®ã¾ã¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NumberOfTrips\n",
    "def preprocess(value):\n",
    "    # å€¤ãŒfloatå‹ã®å ´åˆã¯æ–‡å­—åˆ—ã«å¤‰æ›\n",
    "    if isinstance(value, float):\n",
    "        value = str(value)\n",
    "    # æ•°å­—ã®ã¿ã®å ´åˆ\n",
    "    if re.match(r\"^\\d+$\", value):\n",
    "        return int(value)\n",
    "    \n",
    "    # \"å¹´ã«\"ãŒå«ã¾ã‚Œã‚‹å ´åˆ\n",
    "    elif \"å¹´ã«\" in value:\n",
    "        times = int(re.search(r\"(\\d+)\", value).group(1))\n",
    "        return times \n",
    "    \n",
    "    # \"åŠå¹´ã«\"ãŒå«ã¾ã‚Œã‚‹å ´åˆ\n",
    "    elif \"åŠå¹´ã«\" in value:\n",
    "        times = int(re.search(r\"(\\d+)\", value).group(1))\n",
    "        return times * 2\n",
    "    \n",
    "    # ãã®ä»–ã®å ´åˆã¯Noneã‚’è¿”ã™\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "train['NumberOfTrips'] = train['NumberOfTrips'].apply(preprocess)\n",
    "test['NumberOfTrips'] = test['NumberOfTrips'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passport\n",
    "#ãã®ã¾ã¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PitchSatisfactionScore\n",
    "#ãã®ã¾ã¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Designation(ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°)\n",
    "#ãã®ã¾ã¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MonthlyIncome\n",
    "def clean_income(income):\n",
    "    if pd.isna(income):\n",
    "        return np.nan\n",
    "    income_str = str(income).replace(' ', '').replace(',', '')\n",
    "    if 'ä¸‡å††' in income_str:\n",
    "        num = float(''.join(filter(str.isdigit, income_str)))\n",
    "        return num * 1000\n",
    "    return float(''.join(filter(str.isdigit, income_str))) / 10\n",
    "\n",
    "\n",
    "train['MonthlyIncome'] = train['MonthlyIncome'].apply(clean_income)\n",
    "test['MonthlyIncome'] = test['MonthlyIncome'].apply(clean_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_infoã®å‰å‡¦ç†\n",
    "# å‰å‡¦ç†é–¢æ•°\n",
    "def preprocess(row):\n",
    "    row = re.sub(r'[ã€,ï¼ï¼\\t\\n]', ' ', row)  # åŒºåˆ‡ã‚Šè¨˜å·ã‚’çµ±ä¸€\n",
    "    row = re.sub(r'\\s+', ' ', row).strip()  # ä½™åˆ†ãªç©ºç™½ã‚’å‰Šé™¤\n",
    "    \n",
    "    # å©šå§»çŠ¶æ³\n",
    "    if re.search(r'(æœªå©š)', row):\n",
    "        marital_status = 'æœªå©š'\n",
    "    elif re.search(r'(ç‹¬èº«)',row):\n",
    "        marital_status = 'ç‹¬èº«'\n",
    "    elif re.search(r'(çµå©šæ¸ˆã¿)',row):\n",
    "        marital_status = 'çµå©šæ¸ˆã¿'\n",
    "    elif re.search(r'(é›¢å©šæ¸ˆã¿)',row):\n",
    "        marital_status = 'é›¢å©šæ¸ˆã¿'\n",
    "    else:\n",
    "        marital_status = row\n",
    "    \n",
    "    # è»Šã®æ‰€æœ‰çŠ¶æ³\n",
    "    if re.search(r'(è»Šä¿æœ‰ãªã—|è»Šæœªæ‰€æœ‰|è»Šæœªæ‰€æŒ|è»Šãªã—|ä¹—ç”¨è»Šãªã—)', row):\n",
    "        car_status = 'æœªæ‰€æŒ'\n",
    "    elif re.search(r'(è»Šä¿æœ‰|è»Šæ‰€æŒ|è‡ªå‹•è»Šæ‰€æœ‰|è»Šã‚ã‚Š|è‡ªå®¶ç”¨è»Šã‚ã‚Š)',row):\n",
    "        car_status = 'æ‰€æŒ'\n",
    "    else:\n",
    "        car_status = row\n",
    "    \n",
    "    # å­ä¾›ã®äººæ•°\n",
    "    child_match = re.search(r'(\\d+)(äºº|å…)', row)\n",
    "    child_count = int(child_match.group(1)) if child_match else 0\n",
    "    \n",
    "    return [marital_status, car_status, child_count]\n",
    "\n",
    "train[['married', 'car', 'child']] = train['customer_info'].apply(preprocess).apply(pd.Series)\n",
    "test[['married', 'car', 'child']] = test['customer_info'].apply(preprocess).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ¬ æå€¤ã‚’å¹³å‡å€¤ã§ç½®ãæ›ãˆã‚‹\n",
    "numerical_columns = ['Age', 'DurationOfPitch', 'MonthlyIncome','NumberOfFollowups', 'NumberOfTrips']\n",
    "#å®Ÿé¨“, 'NumberOfFollowups', 'NumberOfTrips'\n",
    "for col in numerical_columns:\n",
    "    median_value = train[col].median()\n",
    "    train[col].fillna(median_value, inplace=True)\n",
    "    test[col].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_bin'] = pd.cut(train['Age'], bins=5, labels=False)\n",
    "test['age_bin'] = pd.cut(test['Age'], bins=5, labels=False)\n",
    "train['income_bin'] = pd.cut(train['MonthlyIncome'], bins=5, labels=False)\n",
    "test['income_bin'] = pd.cut(test['MonthlyIncome'], bins=5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã®é¸æŠ\n",
    "feature_columns = ['Age', 'CityTier', 'NumberOfPersonVisiting',\n",
    "                  'NumberOfFollowups', 'PreferredPropertyStar', 'NumberOfTrips',\n",
    "                  'DurationOfPitch', 'Passport', 'PitchSatisfactionScore', 'MonthlyIncome',\n",
    "                  'TypeofContact', 'Occupation', 'Gender', 'ProductPitched', 'Designation',\n",
    "                  'married', 'car', 'child','age_bin','income_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[feature_columns]\n",
    "y = train['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å±¤åŒ–k-foldã®åˆæœŸåŒ–\n",
    "skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
    "params_cat = {\n",
    "    'iterations': 1000,\n",
    "    'random_seed': 42,\n",
    "    'eval_metric': 'AUC',\n",
    "    'early_stopping_rounds': 50,\n",
    "    'verbose': 100,\n",
    "    'task_type': 'CPU',\n",
    "    'bagging_temperature': 0, \n",
    "    'border_count': 128, \n",
    "    #4\n",
    "    'depth': 1, \n",
    "    'iterations': 200, \n",
    "    'l2_leaf_reg': 3, \n",
    "    'learning_rate': 1, \n",
    "    #0.05\n",
    "    'max_leaves': 31, \n",
    "    'min_data_in_leaf': 1, \n",
    "    'random_strength': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_cat(model, X_new):\n",
    "    \"\"\"\n",
    "    CatBoostãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ç¢ºç‡ã‚’è¿”ã™é–¢æ•°\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : CatBoostClassifier\n",
    "        å­¦ç¿’æ¸ˆã¿ã®CatBoostãƒ¢ãƒ‡ãƒ«\n",
    "    X_new : array-like\n",
    "        äºˆæ¸¬ã—ãŸã„æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    array-like\n",
    "        é™½æ€§ã‚¯ãƒ©ã‚¹ã®äºˆæ¸¬ç¢ºç‡\n",
    "    \"\"\"\n",
    "    return model.predict_proba(X_new)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_auc_cat = []\n",
    "fold_auc_cat_after = []\n",
    "models_cat = []\n",
    "models_cat_cali = []\n",
    "# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰\n",
    "cat_features = ['TypeofContact', \n",
    "                'Occupation', \n",
    "                'Gender',\n",
    "                'Passport',\n",
    "                'ProductPitched', \n",
    "                'Designation' , \n",
    "                'married',\n",
    "                'car',\n",
    "                'age_bin','income_bin',\n",
    "                ]  # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚«ãƒ©ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŒ‡å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "0:\ttest: 0.5058740\tbest: 0.5058740 (0)\ttotal: 2.33ms\tremaining: 465ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8496445966\n",
      "bestIteration = 29\n",
      "\n",
      "Shrink model to first 30 iterations.\n",
      "Fold 1 AUC: 0.8518658681058313\n",
      "Fold 2\n",
      "0:\ttest: 0.5105798\tbest: 0.5105798 (0)\ttotal: 1.64ms\tremaining: 327ms\n",
      "100:\ttest: 0.8307556\tbest: 0.8430960 (52)\ttotal: 135ms\tremaining: 132ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8430959589\n",
      "bestIteration = 52\n",
      "\n",
      "Shrink model to first 53 iterations.\n",
      "Fold 2 AUC: 0.8451526918520469\n",
      "Fold 3\n",
      "0:\ttest: 0.5094116\tbest: 0.5094116 (0)\ttotal: 1.25ms\tremaining: 248ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8432275898\n",
      "bestIteration = 13\n",
      "\n",
      "Shrink model to first 14 iterations.\n",
      "Fold 3 AUC: 0.8441325523232854\n",
      "Fold 4\n",
      "0:\ttest: 0.6986674\tbest: 0.6986674 (0)\ttotal: 1.47ms\tremaining: 293ms\n",
      "100:\ttest: 0.8233005\tbest: 0.8352904 (54)\ttotal: 146ms\tremaining: 143ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8352904311\n",
      "bestIteration = 54\n",
      "\n",
      "Shrink model to first 55 iterations.\n",
      "Fold 4 AUC: 0.8336741762047697\n",
      "Fold 5\n",
      "0:\ttest: 0.7268529\tbest: 0.7268529 (0)\ttotal: 2.09ms\tremaining: 417ms\n",
      "100:\ttest: 0.8272586\tbest: 0.8367583 (68)\ttotal: 148ms\tremaining: 145ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8367582544\n",
      "bestIteration = 68\n",
      "\n",
      "Shrink model to first 69 iterations.\n",
      "Fold 5 AUC: 0.835109014744203\n",
      "Fold 6\n",
      "0:\ttest: 0.6421810\tbest: 0.6421810 (0)\ttotal: 1.37ms\tremaining: 273ms\n",
      "100:\ttest: 0.8841244\tbest: 0.9053666 (62)\ttotal: 126ms\tremaining: 124ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.905366626\n",
      "bestIteration = 62\n",
      "\n",
      "Shrink model to first 63 iterations.\n",
      "Fold 6 AUC: 0.9006827852360062\n",
      "Fold 7\n",
      "0:\ttest: 0.6904377\tbest: 0.6904377 (0)\ttotal: 1.83ms\tremaining: 365ms\n",
      "100:\ttest: 0.8220470\tbest: 0.8239931 (64)\ttotal: 206ms\tremaining: 202ms\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8247517894\n",
      "bestIteration = 103\n",
      "\n",
      "Shrink model to first 104 iterations.\n",
      "Fold 7 AUC: 0.8237622456047763\n"
     ]
    }
   ],
   "source": [
    "# äº¤å·®æ¤œè¨¼\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    \n",
    "    # CatBoostç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
    "    train_pool = Pool(\n",
    "        data=X_train,\n",
    "        label=y_train,\n",
    "        cat_features=cat_features\n",
    "    )\n",
    "    valid_pool = Pool(\n",
    "        data=X_valid,\n",
    "        label=y_valid,\n",
    "        cat_features=cat_features\n",
    "    )\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã¨å­¦ç¿’\n",
    "    model = CatBoostClassifier(**params_cat)\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=valid_pool,\n",
    "        use_best_model=True,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®ç¢ºç‡äºˆæ¸¬\n",
    "    y_pred_prob = predict_proba_cat(model, X_valid)\n",
    "\n",
    "    # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ\n",
    "    calibrated_model = CalibratedClassifierCV(\n",
    "        model, \n",
    "        method='isotonic',  # ã¾ãŸã¯ 'isotonic'\n",
    "        cv='prefit'  # ã™ã§ã«å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨\n",
    "        )\n",
    "    \n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    pred_proba_calibrated = calibrated_model.predict_proba(X_valid)[:, 1]\n",
    "    auc_after = roc_auc_score(y_valid, pred_proba_calibrated)\n",
    "    \n",
    "    # AUCè¨ˆç®—\n",
    "    auc = roc_auc_score(y_valid, y_pred_prob)\n",
    "    print(f\"Fold {fold+1} AUC: {auc_after}\")\n",
    "    fold_auc_cat.append(auc)\n",
    "    fold_auc_cat_after.append(auc_after)\n",
    "    models_cat.append(model)\n",
    "    models_cat_cali.append(calibrated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8496445965512702,\n",
       " 0.8430959589311571,\n",
       " 0.843227589838094,\n",
       " 0.8352904311112577,\n",
       " 0.836758254444701,\n",
       " 0.9053666259854206,\n",
       " 0.8247517894250749,\n",
       " 0.8518658681058313,\n",
       " 0.8451526918520469,\n",
       " 0.8441325523232854,\n",
       " 0.8336741762047697,\n",
       " 0.835109014744203,\n",
       " 0.9006827852360062,\n",
       " 0.8237622456047763]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_auc = fold_auc_cat + fold_auc_cat_after\n",
    "all_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.8480 (Â±0.0238)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x17a1cf470>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x179a87e30>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x171fc2540>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x17a3ef740>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x17a1cd430>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x179d0b5f0>,\n",
       "                        method='isotonic'),\n",
       " CalibratedClassifierCV(cv='prefit',\n",
       "                        estimator=<catboost.core.CatBoostClassifier object at 0x17b3e30e0>,\n",
       "                        method='isotonic'),\n",
       " <catboost.core.CatBoostClassifier at 0x17a1cf470>,\n",
       " <catboost.core.CatBoostClassifier at 0x179a87e30>,\n",
       " <catboost.core.CatBoostClassifier at 0x171fc2540>,\n",
       " <catboost.core.CatBoostClassifier at 0x17a3ef740>,\n",
       " <catboost.core.CatBoostClassifier at 0x17a1cd430>,\n",
       " <catboost.core.CatBoostClassifier at 0x179d0b5f0>,\n",
       " <catboost.core.CatBoostClassifier at 0x17b3e30e0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å…¨foldã®å¹³å‡AUCã‚’è¨ˆç®—\n",
    "mean_auc = np.mean(all_auc)\n",
    "std_auc = np.std(all_auc)\n",
    "print(f\"\\nMean AUC: {mean_auc:.4f} (Â±{std_auc:.4f})\")\n",
    "models_cat_cali_all = models_cat_cali + models_cat\n",
    "models_cat_cali_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬\n",
    "test_preds_cat_cali_all = np.mean([predict_proba_cat(model, test[feature_columns]) for model in models_cat_cali_all], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'ProdTaken': test_preds_cat_cali_all\n",
    "})\n",
    "submission.to_csv('submission_catcali_all_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
